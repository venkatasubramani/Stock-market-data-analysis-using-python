{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1785db6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-20T02:05:19.655085Z",
     "iopub.status.busy": "2023-06-20T02:05:19.654695Z",
     "iopub.status.idle": "2023-06-20T02:05:19.668789Z",
     "shell.execute_reply": "2023-06-20T02:05:19.667953Z"
    },
    "papermill": {
     "duration": 0.022264,
     "end_time": "2023-06-20T02:05:19.670922",
     "exception": false,
     "start_time": "2023-06-20T02:05:19.648658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/yahoo-finance-stock-market-data/stock_market_data.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdf4977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T02:05:19.679683Z",
     "iopub.status.busy": "2023-06-20T02:05:19.678800Z",
     "iopub.status.idle": "2023-06-20T02:06:09.133730Z",
     "shell.execute_reply": "2023-06-20T02:06:09.132121Z"
    },
    "papermill": {
     "duration": 49.46181,
     "end_time": "2023-06-20T02:06:09.136250",
     "exception": false,
     "start_time": "2023-06-20T02:05:19.674440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Building wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317146 sha256=e04376faedb72c40649103a603678a7148b6a86ea37206c85ca3fa3f51743c71\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: pyspark\r\n",
      "Successfully installed pyspark-3.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5a0d26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T02:06:09.161837Z",
     "iopub.status.busy": "2023-06-20T02:06:09.161390Z",
     "iopub.status.idle": "2023-06-20T02:06:14.940650Z",
     "shell.execute_reply": "2023-06-20T02:06:14.938810Z"
    },
    "papermill": {
     "duration": 5.7982,
     "end_time": "2023-06-20T02:06:14.946081",
     "exception": false,
     "start_time": "2023-06-20T02:06:09.147881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/20 02:06:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.sql.window import Window\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# from datetime import datetime\n",
    "sc = SparkContext('local')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89a336f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T02:06:14.985211Z",
     "iopub.status.busy": "2023-06-20T02:06:14.984263Z",
     "iopub.status.idle": "2023-06-20T02:06:22.129070Z",
     "shell.execute_reply": "2023-06-20T02:06:22.127693Z"
    },
    "papermill": {
     "duration": 7.16915,
     "end_time": "2023-06-20T02:06:22.133180",
     "exception": false,
     "start_time": "2023-06-20T02:06:14.964030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+---------+---------+\n",
      "|      Date|     AMZN|     GOOG|     QCOM|     AMAT|\n",
      "+----------+---------+---------+---------+---------+\n",
      "|02/01/2020|94.900497|  68.3685|88.690002|62.200001|\n",
      "|03/01/2020|93.748497|68.032997|87.019997|61.209999|\n",
      "|06/01/2020|95.143997|69.710503|86.510002|59.889999|\n",
      "|07/01/2020|95.343002|   69.667|88.970001|61.619999|\n",
      "|08/01/2020|94.598503|70.216003|88.709999|61.580002|\n",
      "|09/01/2020|95.052498|70.991501|89.910004|61.970001|\n",
      "|10/01/2020|94.157997|71.486504|90.260002|61.470001|\n",
      "|13/01/2020|94.565002|71.961502|90.970001|61.810001|\n",
      "|14/01/2020|   93.472|71.543999|90.559998|62.349998|\n",
      "|15/01/2020|93.100998|71.959999|89.669998|    61.93|\n",
      "|16/01/2020|93.897003|72.584999|91.790001|63.209999|\n",
      "|17/01/2020|   93.236|74.019501|95.910004|62.849998|\n",
      "|21/01/2020|94.599998|74.220001|94.540001|63.200001|\n",
      "|22/01/2020|94.373001|74.297501|92.970001|63.889999|\n",
      "|23/01/2020|94.228996|74.332497|       92|63.889999|\n",
      "|24/01/2020|93.082001|73.335503|89.650002|       62|\n",
      "|27/01/2020|   91.417|   71.695|87.050003|59.049999|\n",
      "|28/01/2020|92.662498|72.627998|89.150002|60.189999|\n",
      "|29/01/2020|92.900002|72.931503|88.230003|    59.82|\n",
      "|30/01/2020|93.533997|   72.792|87.779999|    60.25|\n",
      "+----------+---------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession(sc)\n",
    "df=spark.read.format(\"csv\").option(\"header\",\"true\").load('/kaggle/input/yahoo-finance-stock-market-data/stock_market_data.csv')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a8aee4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T02:06:22.160510Z",
     "iopub.status.busy": "2023-06-20T02:06:22.160080Z",
     "iopub.status.idle": "2023-06-20T02:06:27.480895Z",
     "shell.execute_reply": "2023-06-20T02:06:27.479522Z"
    },
    "papermill": {
     "duration": 5.337832,
     "end_time": "2023-06-20T02:06:27.484182",
     "exception": false,
     "start_time": "2023-06-20T02:06:22.146350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/20 02:06:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+---------+---------+\n",
      "|      Date|     AMZN|     GOOG|     QCOM|     AMAT|\n",
      "+----------+---------+---------+---------+---------+\n",
      "|2020-01-02|94.900497|94.900497|94.900497|94.900497|\n",
      "|2020-01-03|93.748497|93.748497|93.748497|93.748497|\n",
      "|2020-01-04|93.748497|93.748497|93.748497|93.748497|\n",
      "|2020-01-05|93.748497|93.748497|93.748497|93.748497|\n",
      "|2020-01-06|95.143997|95.143997|95.143997|95.143997|\n",
      "|2020-01-07|95.343002|95.343002|95.343002|95.343002|\n",
      "|2020-01-08|94.598503|94.598503|94.598503|94.598503|\n",
      "|2020-01-09|95.052498|95.052498|95.052498|95.052498|\n",
      "|2020-01-10|94.157997|94.157997|94.157997|94.157997|\n",
      "|2020-01-11|94.157997|94.157997|94.157997|94.157997|\n",
      "|2020-01-12|94.157997|94.157997|94.157997|94.157997|\n",
      "|2020-01-13|94.565002|94.565002|94.565002|94.565002|\n",
      "|2020-01-14|   93.472|   93.472|   93.472|   93.472|\n",
      "|2020-01-15|93.100998|93.100998|93.100998|93.100998|\n",
      "|2020-01-16|93.897003|93.897003|93.897003|93.897003|\n",
      "|2020-01-17|   93.236|   93.236|   93.236|   93.236|\n",
      "|2020-01-18|   93.236|   93.236|   93.236|   93.236|\n",
      "|2020-01-19|   93.236|   93.236|   93.236|   93.236|\n",
      "|2020-01-20|   93.236|   93.236|   93.236|   93.236|\n",
      "|2020-01-21|94.599998|94.599998|94.599998|94.599998|\n",
      "+----------+---------+---------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "df = df.withColumn(\"Date\", F.to_date(F.col(\"Date\"), 'dd/MM/yyyy'))\n",
    "min_date = df.select(F.min(\"Date\")).first()[0]\n",
    "max_date = df.select(F.max(\"Date\")).first()[0]\n",
    "date_range = [min_date + datetime.timedelta(days=x) for x in range((max_date - min_date).days + 1)]\n",
    "all_dates_df = spark.createDataFrame([(date,) for date in date_range], [\"Date\"])\n",
    "full_df = all_dates_df.join(df, on=\"Date\", how=\"left_outer\").orderBy(\"Date\")\n",
    "window = (Window.orderBy('Date').rowsBetween(Window.unboundedPreceding, Window.currentRow))\n",
    "full_df = (full_df.withColumn('AMZN', F.last('AMZN', ignorenulls=True).over(window)))\n",
    "full_df = (full_df.withColumn('GOOG', F.last('AMZN', ignorenulls=True).over(window)))\n",
    "full_df = (full_df.withColumn('QCOM', F.last('AMZN', ignorenulls=True).over(window)))\n",
    "full_df = (full_df.withColumn('AMAT', F.last('AMZN', ignorenulls=True).over(window)))\n",
    "    \n",
    "full_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d3ff0c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T02:06:27.516203Z",
     "iopub.status.busy": "2023-06-20T02:06:27.515819Z",
     "iopub.status.idle": "2023-06-20T02:06:28.751665Z",
     "shell.execute_reply": "2023-06-20T02:06:28.750281Z"
    },
    "papermill": {
     "duration": 1.253418,
     "end_time": "2023-06-20T02:06:28.755281",
     "exception": false,
     "start_time": "2023-06-20T02:06:27.501863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/20 02:06:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/06/20 02:06:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "full_df.toPandas().to_csv('pre_processed_data.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168e88d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-20T02:06:28.794733Z",
     "iopub.status.busy": "2023-06-20T02:06:28.793549Z",
     "iopub.status.idle": "2023-06-20T02:06:28.842652Z",
     "shell.execute_reply": "2023-06-20T02:06:28.841679Z"
    },
    "papermill": {
     "duration": 0.071538,
     "end_time": "2023-06-20T02:06:28.844920",
     "exception": false,
     "start_time": "2023-06-20T02:06:28.773382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>QCOM</th>\n",
       "      <th>AMAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "      <td>94.900497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "      <td>93.748497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>95.143997</td>\n",
       "      <td>95.143997</td>\n",
       "      <td>95.143997</td>\n",
       "      <td>95.143997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       AMZN       GOOG       QCOM       AMAT\n",
       "0  2020-01-02  94.900497  94.900497  94.900497  94.900497\n",
       "1  2020-01-03  93.748497  93.748497  93.748497  93.748497\n",
       "2  2020-01-04  93.748497  93.748497  93.748497  93.748497\n",
       "3  2020-01-05  93.748497  93.748497  93.748497  93.748497\n",
       "4  2020-01-06  95.143997  95.143997  95.143997  95.143997"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data = pd.read_csv('/kaggle/working/pre_processed_data.csv')\n",
    "stock_data = stock_data.drop(columns=['Unnamed: 0'])\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b3e3f",
   "metadata": {
    "papermill": {
     "duration": 0.012096,
     "end_time": "2023-06-20T02:06:28.871145",
     "exception": false,
     "start_time": "2023-06-20T02:06:28.859049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "THE SHARE PRICES ARE IN POUNDS AND NOT IN DOLLARS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8386d7a",
   "metadata": {
    "papermill": {
     "duration": 0.011782,
     "end_time": "2023-06-20T02:06:28.895349",
     "exception": false,
     "start_time": "2023-06-20T02:06:28.883567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Autoregression (AR) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263d5d2",
   "metadata": {
    "papermill": {
     "duration": 0.012208,
     "end_time": "2023-06-20T02:06:28.920343",
     "exception": false,
     "start_time": "2023-06-20T02:06:28.908135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6dc964",
   "metadata": {
    "papermill": {
     "duration": 0.011972,
     "end_time": "2023-06-20T02:06:28.944507",
     "exception": false,
     "start_time": "2023-06-20T02:06:28.932535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 83.865672,
   "end_time": "2023-06-20T02:06:31.581351",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-20T02:05:07.715679",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
